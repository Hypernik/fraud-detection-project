# -*- coding: utf-8 -*-
"""Fraud_Detection_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r27Vo4Qe4BmkZk3GSsDx821kTOCq-VSp
"""

import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns

print("Libraries installed successfully!")

import os
# point to present directory
directory = os.getcwd()
files = os.listdir(directory)
print(files)

"""Data Loading and Initial Exploration"""

import pandas as pd


df = pd.read_csv('credit_card_transactions.csv')


df.head()

df.info()

df.isnull().sum()

df.describe()

import seaborn as sns
import matplotlib.pyplot as plt

print(df.columns)

plt.title('Class Distribution')
plt.show()

plt.figure(figsize=(6,4))


sns.countplot(x='is_fraud', data=df, palette='Set2')

plt.title('Fraud vs Non-Fraud Transactions', fontsize=14)
plt.xlabel('Transaction Type (0 = Non-Fraud, 1 = Fraud)', fontsize=12)
plt.ylabel('Count', fontsize=12)


for i, count in enumerate(df['is_fraud'].value_counts()):
    plt.text(i, count + 500, str(count), ha='center', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.show()

"""Data Preprocessing"""

df.dropna(inplace=True)

df.isnull().sum()

print(f"Number of rows before drop: {len(df)}")
df.dropna(inplace=True)
print(f"Number of rows after drop: {len(df)}")

from sklearn.impute import SimpleImputer

numeric_cols = df.select_dtypes(include=['number']).columns
categorical_cols = df.select_dtypes(exclude=['number']).columns

numeric_imputer = SimpleImputer(strategy='mean')
df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])

categorical_imputer = SimpleImputer(strategy='most_frequent')
df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])

print(df.head())

print(df.isnull().sum())

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df['amt'] = scaler.fit_transform(df[['amt']])
print(df.head())

""" Exploratory Data Analysis (EDA)"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x='is_fraud', data=df)
plt.title('Class Distribution')
plt.show()

"""Handling Class Imbalance

"""

import pandas as pd

df = pd.read_csv('credit_card_transactions.csv')

numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

for column in df.select_dtypes(include=['object']).columns:
    df[column] = label_encoder.fit_transform(df[column])

print(df.head())

"""Model Building
Training a Random Forest Model
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

model = RandomForestClassifier(class_weight='balanced')

X = df.drop(columns=['is_fraud'])
y = df['is_fraud']
print(X.head())
print(y.head())

from sklearn.preprocessing import LabelEncoder

X_encoded = X.copy()

label_encoder = LabelEncoder()

for column in X_encoded.select_dtypes(include=['object']).columns:
    X_encoded[column] = label_encoder.fit_transform(X_encoded[column])

print(X_encoded.head())

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

model = RandomForestClassifier(n_estimators=10, random_state=42, class_weight='balanced')

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=10, random_state=42, class_weight='balanced')

model.fit(X_train, y_train)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=10, random_state=42, class_weight='balanced', n_jobs=-1)

model.fit(X_train, y_train)

print("Model trained successfully!")

y_pred = model.predict(X_test)
from sklearn.metrics import accuracy_score, classification_report

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""Model Evaluation"""

from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""XGBoost"""

from xgboost import XGBClassifier

xgb_model = XGBClassifier()
xgb_model.fit(X_train, y_train)

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X_train, y_train, cv=5)
print(scores.mean())

"""Feature Importance"""

importances = model.feature_importances_
feature_names = X.columns
feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})
feature_importance_df.sort_values(by='importance', ascending=False, inplace=True)
print(feature_importance_df)

"""Save the Model"""

import joblib

X_encoded = X.copy()
label_encoders = {}
for column in X_encoded.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    X_encoded[column] = le.fit_transform(X_encoded[column])
    label_encoders[column] = le 

joblib.dump(model, 'fraud_detection_model.pkl')
joblib.dump(label_encoders, 'label_encoders.pkl')  # DICTIONARY of encoders
joblib.dump(X_encoded.columns.tolist(), 'feature_columns.pkl')
